@book{sutton-barto,
  title = {Reinforcement Learning: An Introduction},
  publisher = {MIT Press},
  year = {2018},
  added-at = {2019-07-13T10:11:53.000+0200},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  biburl = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  edition = {2nd edition}
}

@article{alphastar,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{wang2021scc,
  title={SCC: An efficient deep reinforcement learning agent mastering the game of StarCraft II},
  author={Wang, Xiangjun and Song, Junxiao and Qi, Penghui and Peng, Peng and Tang, Zhenkun and Zhang, Wei and Li, Weimin and Pi, Xiongjun and He, Jujie and Gao, Chao and others},
  booktitle={International conference on machine learning},
  pages={10905--10915},
  year={2021},
  organization={PMLR}
}

@article{open-ai-five,
  author    = {Christopher Berner and
               Greg Brockman and
               Brooke Chan and
               Vicki Cheung and
               Przemyslaw Debiak and
               Christy Dennison and
               David Farhi and
               Quirin Fischer and
               Shariq Hashme and
               Christopher Hesse and
               Rafal J{\'{o}}zefowicz and
               Scott Gray and
               Catherine Olsson and
               Jakub Pachocki and
               Michael Petrov and
               Henrique Pond{\'{e}} de Oliveira Pinto and
               Jonathan Raiman and
               Tim Salimans and
               Jeremy Schlatter and
               Jonas Schneider and
               Szymon Sidor and
               Ilya Sutskever and
               Jie Tang and
               Filip Wolski and
               Susan Zhang},
  title     = {Dota 2 with Large Scale Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1912.06680},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.06680},
  eprinttype = {arXiv},
  eprint    = {1912.06680},
  timestamp = {Wed, 03 Jun 2020 10:56:28 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1912-06680.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{alphago-fan,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}


@misc{minecraft-vpt,
  doi = {10.48550/ARXIV.2206.11795},
  
  url = {https://arxiv.org/abs/2206.11795},
  
  author = {Baker, Bowen and Akkaya, Ilge and Zhokhov, Peter and Huizinga, Joost and Tang, Jie and Ecoffet, Adrien and Houghton, Brandon and Sampedro, Raul and Clune, Jeff},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{dreamer-v3,
  doi = {10.48550/ARXIV.2301.04104},
  
  url = {https://arxiv.org/abs/2301.04104},
  
  author = {Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  
  keywords = {Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Mastering Diverse Domains through World Models},
  
  publisher = {arXiv},
  
  year = {2023},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{instruct-gpt,
  doi = {10.48550/ARXIV.2203.02155},
  
  url = {https://arxiv.org/abs/2203.02155},
  
  author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Training language models to follow instructions with human feedback},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@article{greensmith2004variance,
  title={Variance Reduction Techniques for Gradient Estimates in Reinforcement Learning.},
  author={Greensmith, Evan and Bartlett, Peter L and Baxter, Jonathan},
  journal={Journal of Machine Learning Research},
  volume={5},
  number={9},
  year={2004}
}

@article{huang2022cleanrl,
  author  = {Shengyi Huang and Rousslan Fernand Julien Dossa and Chang Ye and Jeff Braga and Dipam Chakraborty and Kinal Mehta and João G.M. Araújo},
  title   = {CleanRL: High-quality Single-file Implementations of Deep Reinforcement Learning Algorithms},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {274},
  pages   = {1--18},
  url     = {http://jmlr.org/papers/v23/21-1342.html}
}

@article{stable-baselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}

@article{tianshou,
  author  = {Jiayi Weng and Huayu Chen and Dong Yan and Kaichao You and Alexis Duburcq and Minghao Zhang and Yi Su and Hang Su and Jun Zhu},
  title   = {Tianshou: A Highly Modularized Deep Reinforcement Learning Library},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {267},
  pages   = {1--6},
  url     = {http://jmlr.org/papers/v23/21-1127.html}
}

@misc{briscola-wikipedia,
  author = "Wikipedia",
  title = "Briscola --- Wikipedia{,} The free encyclopedia",
  year = "2023",
  url = "https://en.wikipedia.org/wiki/Briscola",
}

@misc{briscola-rule-based,
  author = "Solitari con le carte",
  title = "Briscola --- Wikipedia{,} The free encyclopedia",
  year = "2023",
  url = "http://www.solitariconlecarte.it/briscola_2classica.htm",
}

@misc{fezriva-briscola-dqn,
  author = {fezriva},
  title = {Briscola},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/fezriva/briscola}}
}

@misc{alsora-deep-briscola-dqn,
  author = {alsora},
  title = {deep-briscola},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/alsora/deep-briscola}}
}

 @article{villa2013-briscola-mcts,
  title={Algoritmi di ricerca ad albero Monte Carlo applicati all'intelligenza artificiale nel gioco della briscola a cinque},
  author={VILLA, ANDREA},
  year={2013}
}

@article{Briscola-mcts-Playing-Algorithm,
  title={A Game-Playing Algorithm for Briscola},
  author={Gazda, Samuel},
  year={2021}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{td-gammon,
  title={Temporal difference learning and TD-Gammon},
  author={Tesauro, Gerald and others},
  journal={Communications of the ACM},
  volume={38},
  number={3},
  pages={58--68},
  year={1995}
}

@article{alphazero,
  title={Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={arXiv preprint arXiv:1712.01815},
  year={2017}
}

@article{alphagozero,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{muzero,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{libratus,
  title={Superhuman AI for heads-up no-limit poker: Libratus beats top professionals},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Science},
  volume={359},
  number={6374},
  pages={418--424},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{cfr,
  title={Regret minimization in games with incomplete information},
  author={Zinkevich, Martin and Johanson, Michael and Bowling, Michael and Piccione, Carmelo},
  journal={Advances in neural information processing systems},
  volume={20},
  year={2007}
}

@article{rebel,
  title={Combining deep reinforcement learning and search for imperfect-information games},
  author={Brown, Noam and Bakhtin, Anton and Lerer, Adam and Gong, Qucheng},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17057--17069},
  year={2020}
}

@misc{stockfish,
  author = {Stockfish Development Team},
  title = {Stockfish},
  year = {2023},
  howpublished = {\url{https://stockfishchess.org/}}
}

@misc{lc0,
  title={Lc0: Open-Source Neural Network Chess Engine},
  author={The Lc0 Team},
  howpublished={\url{https://lczero.org/}},
  year={2023}
}

@misc{nash-equilibrium-wikipedia,
  author = "Wikipedia",
  title = "Nash equilibrium --- Wikipedia{,} The free encyclopedia",
  year = "2023",
  url = "https://en.wikipedia.org/wiki/Nash_equilibrium",
}

@book{norvig-russell,
  title={Artificial Intelligence: A Modern Approach},
  edition={4th},
  author={Russell, Stuart and Norvig, Peter},
  year={2021},
  publisher={Pearson Education Limited, London}
}

@Inbook{marl,
author="Bu{\c{s}}oniu, Lucian
and Babu{\v{s}}ka, Robert
and De Schutter, Bart",
editor="Srinivasan, Dipti
and Jain, Lakhmi C.",
title="Multi-agent Reinforcement Learning: An Overview",
bookTitle="Innovations in Multi-Agent Systems and Applications - 1",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="183--221",
abstract="Multi-agent systems can be used to address problems in a variety of domains, including robotics, distributed control, telecommunications, and economics. The complexity of many tasks arising in these domains makes them difficult to solve with preprogrammed agent behaviors. The agents must instead discover a solution on their own, using learning. A significant part of the research on multi-agent learning concerns reinforcement learning techniques. This chapter reviews a representative selection of multi-agent reinforcement learning algorithms for fully cooperative, fully competitive, and more general (neither cooperative nor competitive) tasks. The benefits and challenges of multi-agent reinforcement learning are described. A central challenge in the field is the formal statement of a multi-agent learning goal; this chapter reviews the learning goals proposed in the literature. The problem domains where multi-agent reinforcement learning techniques have been applied are briefly discussed. Several multi-agent reinforcement learning algorithms are applied to an illustrative example involving the coordinated transportation of an object by two cooperative robots. In an outlook for the multi-agent reinforcement learning field, a set of important open issues are identified, and promising research directions to address these issues are outlined.",
isbn="978-3-642-14435-6",
doi="10.1007/978-3-642-14435-6_7",
url="https://doi.org/10.1007/978-3-642-14435-6_7"
}

